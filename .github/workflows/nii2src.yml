name: STEP T1 NII to SRC

on:
  workflow_dispatch:
    inputs:
      dataset_id:
        description: 'OpenNeuro Accession Number'
        default: ds001378
        required: true
      rev_pe:
        description: 'Reverse Phase Encoding File'
        default: ''
  workflow_call:
    inputs:
      dataset_id:
        description: 'OpenNeuro Accession Number'
        default: ds001378
        required: true
        type: string

jobs:
  nii2src:
    runs-on: ubuntu-20.04
    strategy:
      matrix:
        batch: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
      fail-fast: false
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      - name: Cache FSL environment
        id: cache-fsl
        uses: actions/cache@v3
        with:
          path: /opt/fsl
          key: ${{ runner.os }}-fsl6.0.5.2
      - name: Prepare FSL environment
        if: steps.cache-fsl.outputs.cache-hit != 'true'
        run: curl -sSL https://fsl.fmrib.ox.ac.uk/fsldownloads/fsl-6.0.5.2-centos7_64.tar.gz | tar zxv --no-same-owner -C /opt --exclude='fsl/doc' --exclude='fsl/refdoc' --exclude='fsl/python/oxford_asl' --exclude='fsl/data/possum' --exclude='fsl/data/first' --exclude='fsl/data/mist' --exclude='fsl/data/atlases' --exclude='fsl/data/xtract_data' --exclude='fsl/extras/doc' --exclude='fsl/extras/man' --exclude='fsl/extras/src' --exclude='fsl/src'
      - name: Download NIFTI and Convert
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          curl -sL "https://github.com/frankyeh/DSI-Studio/releases/download/2024.06.12/dsi_studio_ubuntu2004.zip" | jar x && chmod 777 ./dsi-studio/dsi_studio
          export OS="Linux"
          export FSLDIR="/opt/fsl"
          export FSL_DIR="$FSLDIR"
          export FSLOUTPUTTYPE="NIFTI_GZ"
          export FSLMULTIFILEQUIT="TRUE"
          export LD_LIBRARY_PATH="$FSLDIR/lib:$LD_LIBRARY_PATH"
          export FSLTCLSH="/usr/bin/tclsh"
          export FSLWISH="/usr/bin/wish"
          export PATH="$FSLDIR/bin:$PATH"

          
          subjects=($(aws s3 ls --no-sign-request --region eu-west-1 s3://openneuro.org/${{ inputs.dataset_id }} --recursive | grep '/dwi/' | grep 'nii.gz' | awk '{print $NF}' | awk -F'/dwi/' '{print $1}' | awk -F'/sub-' '/sub-/ {print "sub-" $2}' | sort -u ))
          for (( i=${{ matrix.batch }}; i< ${#subjects[@]}; i+=16 )); do
            subject=${subjects[i]}
            file=$(echo ${subject} | tr '/' '_')
            echo "Processing $file"
            if curl --head --silent --fail https://github.com/frankyeh/DSI-Studio-Cloud/releases/download/${{ inputs.dataset_id }}/${file}_dwi.src.gz; then
              echo "$file exists."
            else
              echo "Downloading and processing ${subject}"
              aws s3 sync --quiet --no-sign-request --region eu-west-1 --exclude "*" --include "*dwi*" s3://openneuro.org/${{ inputs.dataset_id }}/${subject} ${subject}
              ./dsi-studio/dsi_studio --action=src --bids=1 --source=./${subject}/dwi
              
              count=1
              for src in ./${subject}/dwi/*.src.gz; do
                if [ $count -eq 1 ]; then
                  mv "$src" "./${file}_dwi.raw.src.gz"
                else
                  mv "$src" "./${file}_dwi.${count}.raw.src.gz"
                fi
                # Check for corresponding .rsrc.gz file
                rsrc_file="${src%.src.gz}.rsrc.gz"
                if [ -e "$rsrc_file" ]; then
                  echo "has rsrc file $rsrc_file";
                  if [ $count -eq 1 ]; then
                    mv "$rsrc_file" "./${file}_dwi.raw.rsrc.gz"
                  else
                    mv "$rsrc_file" "./${file}_dwi.${count}.raw.rsrc.gz"
                  fi
                fi
                count=$((count + 1))
              done
              rm -fr ./${subject}
              
              if [ "${{ inputs.rev_pe }}" != "" ]; then
                if [ "${{ inputs.rev_pe }}" == "skip" ]; then
                  for file in *.raw.src.gz; do
                    mv "$file" "${file/.raw.src.gz/.src.gz}"
                  done
                else
                  echo "get the additional file for topup"
                  aws s3 sync --quiet --no-sign-request --region eu-west-1 --exclude "*" --include "*${subject}${{ inputs.rev_pe }}" s3://openneuro.org/${{ inputs.dataset_id }}/ ${subject}
                  find ./${subject} -type f -exec mv {} . \;
                  rm -fr ./${subject}
                  ls *.*
                  mv *.nii.gz rev_pe.nii.gz
                  ./dsi-studio/dsi_studio --action=rec --source=./*.raw.src.gz --rev_pe=rev_pe.nii.gz --save_src=./*.src.gz
                fi
              else
                ./dsi-studio/dsi_studio --action=rec --source=./*.raw.src.gz --cmd="[Step T2][Corrections][TOPUP EDDY]" --save_src=./*.src.gz
              fi

              rm *.raw.src.gz || true
              gh release upload "${{ inputs.dataset_id }}" ./*.src.gz || gh release upload "${{ inputs.dataset_id }}" ./*.src.gz
              rm *.*
            fi
          done
